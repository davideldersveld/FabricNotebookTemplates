{"cells":[{"cell_type":"code","source":["import sempy.fabric as fabric\n","import pandas as pd\n","from datetime import datetime\n","\n","# Use Semantic Link to connect to Fabric REST API\n","client = fabric.FabricRestClient()\n","\n","# Define function to obtain admin Tenant Settings and save from sample dataframes to file or table\n","def get_tenant_settings():\n","\n","    # URL to API endpoint\n","    fabric_api_url = \"v1/admin/tenantsettings\"\n","\n","    # Request\n","    response = client.get(fabric_api_url)\n","\n","    try:\n","        # Add to pandas dataframe\n","        df = pd.json_normalize(response.json()['tenantSettings'])\n","\n","        # Sample save from pandas dataframe to Fabric lakehouse file as standard parquet\n","        now_date = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n","        data_context = \"FabricTenantSettings\"\n","        lakehouse_path = \"/lakehouse/default/Files/\"\n","        lakehouse_file = f\"{data_context} {now_date}.parquet\"\n","\n","        df.to_parquet(f\"{lakehouse_path}/{lakehouse_file}\")\n","\n","        # Alternative sample save to Delta format lakehouse table now accessible via SQL endpoint\n","        df_spark = spark.createDataFrame(df)\n","        df_spark.write.mode(\"overwrite\").format(\"delta\").saveAsTable(data_context)\n","\n","    except: \n","        print(\"Could not validate tenant settings or check if Lakehouse added to Notebook\")\n","\n","# Execute function\n","get_tenant_settings()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":null,"statement_ids":null,"livy_statement_state":null,"session_id":null,"state":"waiting","normalized_state":"waiting","queued_time":"2024-06-28T17:22:13.2268813Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"b80f6814-b784-42fd-bb68-43bf4aca7b31"},"text/plain":"StatementMeta(, , , Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5762dab6-f417-498e-a664-ca3237ab565b"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"ddbd8cc1-90a2-41de-96d8-64f0dc5b3371","default_lakehouse_name":"AdminToolHouse","default_lakehouse_workspace_id":"8ef8a063-6352-4df3-8766-59b57c27c21a"}}},"nbformat":4,"nbformat_minor":5}